{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython.display as ipd\n",
    "\n",
    "for filename in os.listdir('./test_audio'):\n",
    "    ipd.Audio('./test_audio/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "for filename in os.listdir('./test'):\n",
    "    data, sampling_rate = librosa.load('./test/' + filename)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = sr.AudioFile('0_jackson_2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zero as source:\n",
    "    audio = r.record(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.recognize_google(audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the main training part:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training with audio files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports:\n",
    "\n",
    "from export_model import *\n",
    "from preprocess import *\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 15  #11\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=feature_dim_2)\n",
    "\n",
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "# # Feature dimension\n",
    "#defaults at the end\n",
    "feature_dim_1 = 20   #20\n",
    "channel = 1          #1\n",
    "epochs = 50          #50\n",
    "batch_size = 50      #100\n",
    "verbose = 1          #1\n",
    "# change num_classes depending on the amount of labels\n",
    "num_classes = 12\n",
    "\n",
    "# Reshaping to perform 2D convolution\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model & prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(GaussianNoise(stddev=2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Predicts one sample\n",
    "def predict(filepath, model):\n",
    "    sample = wav2mfcc(filepath, feature_dim_2)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    return get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "history = model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export current model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export_model(model)\n",
    "\n",
    "y_predicted = model.predict_classes(X_test, batch_size=batch_size)\n",
    "y_true_val = np.argmax(y_test_hot,axis=1)\n",
    "\n",
    "class_rep = classification_report(y_true_val,y_predicted,digits=5)\n",
    "\n",
    "settings = {\n",
    "    \"feature_dim_1\": feature_dim_1,\n",
    "    \"feature_dim_2\": feature_dim_2,\n",
    "    \"channel\": channel,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"train_accuracy\": str(history.history.get('acc')[-1]),\n",
    "    \"test_accuracy\": str(history.history.get('val_acc')[-1]),\n",
    "    \"train_loss\": str(history.history.get('loss')[-1]),\n",
    "    \"test_loss\": str(history.history.get('val_loss')[-1]),\n",
    "    \"classification_report\": class_rep,\n",
    "}\n",
    "\n",
    "print(export_model(model, settings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import_model(PATH)\n",
    "imported_model = import_model(\"./models/xxx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on a new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(predict('./test_audio/12.wav', model=model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on a folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "FOLDER_PATH = './test_audio/'\n",
    "\n",
    "truefalse = {'True': 0, 'False': 0}\n",
    "\n",
    "for filename in os.listdir(FOLDER_PATH):\n",
    "    pred = predict(FOLDER_PATH + filename, model=model)\n",
    "    number = re.match(r\"[^_]*\", filename)\n",
    "    correct = number.group(0) == pred\n",
    "    truefalse[str(correct)] += 1\n",
    "    print(\"Correct: \" + str(correct) + \" --> \" + filename + \" was predicted as: \" + pred)\n",
    "    \n",
    "print(truefalse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy / Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Accuracy plot\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#Loss plot\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full report with confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#should import labels directly from folder:\n",
    "labels, _, _= get_labels(\"./audio\")\n",
    "labArray = []\n",
    "for label in labels:\n",
    "    labArray.append(label)\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit_transform(labArray)\n",
    "\n",
    "full_multiclass_report(model, X_test, y_test_hot, classes=le.inverse_transform(np.arange(12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for all the metrics and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title='Normalized confusion matrix'\n",
    "    else:\n",
    "        title='Confusion matrix'\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "def full_multiclass_report(model,\n",
    "                           x,\n",
    "                           y_true,\n",
    "                           classes,\n",
    "                           batch_size=32,\n",
    "                           binary=False):\n",
    "\n",
    "    # 1. Transform one-hot encoded y_true into their class number\n",
    "    if not binary:\n",
    "        y_true = np.argmax(y_true,axis=1)\n",
    "    \n",
    "    # 2. Predict classes and stores in y_pred\n",
    "    y_pred = model.predict_classes(x, batch_size=batch_size)\n",
    "    \n",
    "    # 3. Print accuracy score\n",
    "    print(\"Accuracy : \"+ str(accuracy_score(y_true,y_pred)))\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    # 4. Print classification report\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_true,y_pred,digits=5))    \n",
    "    \n",
    "    # 5. Plot confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_true,y_pred)\n",
    "    print(cnf_matrix)\n",
    "    plot_confusion_matrix(cnf_matrix,classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example Swiss German - Standard German data (you would extract this from your JSON)\n",
    "data = [\n",
    "    {\"swiss_german\": \"I bi am abend\", \"standard_german\": \"Ich bin am Abend\"},\n",
    "    {\"swiss_german\": \"Chunsch au?\", \"standard_german\": \"Kommst du auch?\"},\n",
    "    # Add more data...\n",
    "]\n",
    "\n",
    "# Extract the Swiss German and Standard German texts\n",
    "swiss_german_texts = [item['swiss_german'] for item in data]\n",
    "standard_german_texts = [item['standard_german'] for item in data]\n",
    "\n",
    "# Tokenizer initialization and fitting\n",
    "src_tokenizer = Tokenizer(filters='')  # Don't filter anything\n",
    "tgt_tokenizer = Tokenizer(filters='')\n",
    "\n",
    "src_tokenizer.fit_on_texts(swiss_german_texts)\n",
    "tgt_tokenizer.fit_on_texts(standard_german_texts)\n",
    "\n",
    "# Convert texts to sequences of integers\n",
    "src_sequences = src_tokenizer.texts_to_sequences(swiss_german_texts)\n",
    "tgt_sequences = tgt_tokenizer.texts_to_sequences(standard_german_texts)\n",
    "\n",
    "# Add start and end tokens to the target sequences (for sequence-to-sequence)\n",
    "START_TOKEN = tgt_tokenizer.word_index['<start>'] if '<start>' in tgt_tokenizer.word_index else 1\n",
    "END_TOKEN = tgt_tokenizer.word_index['<end>'] if '<end>' in tgt_tokenizer.word_index else 2\n",
    "\n",
    "tgt_sequences = [[START_TOKEN] + seq + [END_TOKEN] for seq in tgt_sequences]\n",
    "\n",
    "# Padding sequences to ensure they are all the same length\n",
    "MAX_SEQ_LEN = 49  # Set this according to the average length of your sentences\n",
    "src_sequences = pad_sequences(src_sequences, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "tgt_sequences = pad_sequences(tgt_sequences, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_val, y_train, y_val = train_test_split(src_sequences, tgt_sequences, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def get_position_encoding(seq_len, d_model):\n",
    "    \"\"\"Generates positional encoding for the given sequence length and model dimension.\"\"\"\n",
    "    pos = np.arange(seq_len)[:, np.newaxis]\n",
    "    i = np.arange(d_model)[np.newaxis, :]\n",
    "    angle_rads = pos / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    \n",
    "    # Apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    # Apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    return K.constant(angle_rads, dtype=tf.float32)\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, seq_len, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.position_encoding = get_position_encoding(seq_len, d_model)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return inputs + self.position_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 49)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 49, 256)      2048        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " positional_encoding_3 (Positio  (None, 49, 256)     0           ['embedding_3[0][0]']            \n",
      " nalEncoding)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (Multi  (None, 49, 256)     2103552     ['positional_encoding_3[0][0]',  \n",
      " HeadAttention)                                                   'positional_encoding_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 49, 256)      0           ['multi_head_attention_12[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (TFOpL  (None, 49, 256)     0           ['positional_encoding_3[0][0]',  \n",
      " ambda)                                                           'dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 49, 256)     512         ['tf.__operators__.add_24[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 49, 512)      131584      ['layer_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 49, 512)      0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 49, 256)      131328      ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (TFOpL  (None, 49, 256)     0           ['layer_normalization_24[0][0]', \n",
      " ambda)                                                           'dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 49, 256)     512         ['tf.__operators__.add_25[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_13 (Multi  (None, 49, 256)     2103552     ['layer_normalization_25[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 49, 256)      0           ['multi_head_attention_13[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (TFOpL  (None, 49, 256)     0           ['layer_normalization_25[0][0]', \n",
      " ambda)                                                           'dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_26 (LayerN  (None, 49, 256)     512         ['tf.__operators__.add_26[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 49, 512)      131584      ['layer_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 49, 512)      0           ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 49, 256)      131328      ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (TFOpL  (None, 49, 256)     0           ['layer_normalization_26[0][0]', \n",
      " ambda)                                                           'dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, 49, 256)     512         ['tf.__operators__.add_27[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (Multi  (None, 49, 256)     2103552     ['layer_normalization_27[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 49, 256)      0           ['multi_head_attention_14[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (TFOpL  (None, 49, 256)     0           ['layer_normalization_27[0][0]', \n",
      " ambda)                                                           'dropout_28[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, 49, 256)     512         ['tf.__operators__.add_28[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 49, 512)      131584      ['layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 49, 512)      0           ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 49, 256)      131328      ['dropout_29[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (TFOpL  (None, 49, 256)     0           ['layer_normalization_28[0][0]', \n",
      " ambda)                                                           'dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, 49, 256)     512         ['tf.__operators__.add_29[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_15 (Multi  (None, 49, 256)     2103552     ['layer_normalization_29[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, 49, 256)      0           ['multi_head_attention_15[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (TFOpL  (None, 49, 256)     0           ['layer_normalization_29[0][0]', \n",
      " ambda)                                                           'dropout_30[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, 49, 256)     512         ['tf.__operators__.add_30[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 49, 512)      131584      ['layer_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)           (None, 49, 512)      0           ['dense_31[0][0]']               \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 49, 256)      131328      ['dropout_31[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (TFOpL  (None, 49, 256)     0           ['layer_normalization_30[0][0]', \n",
      " ambda)                                                           'dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_31 (LayerN  (None, 49, 256)     512         ['tf.__operators__.add_31[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 49)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 49, 8)        2056        ['layer_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,474,056\n",
      "Trainable params: 9,474,056\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LayerNormalization, Dense, Dropout, MultiHeadAttention\n",
    "\n",
    "def transformer_encoder(inputs, num_heads, d_model, ff_dim):\n",
    "    # Multi-Head Attention\n",
    "    attention = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(inputs, inputs)\n",
    "    attention = Dropout(0.1)(attention)\n",
    "    attention = LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "    \n",
    "    # Feed Forward Network\n",
    "    ffn = Dense(ff_dim, activation='relu')(attention)\n",
    "    ffn = Dropout(0.1)(ffn)\n",
    "    ffn = Dense(d_model)(ffn)\n",
    "    ffn = LayerNormalization(epsilon=1e-6)(attention + ffn)\n",
    "    \n",
    "    return ffn\n",
    "\n",
    "def transformer_model(src_vocab_size, tgt_vocab_size, seq_len, d_model=256, num_heads=8, num_layers=4, ff_dim=512):\n",
    "    # Input layers\n",
    "    src_inputs = Input(shape=(seq_len,))\n",
    "    tgt_inputs = Input(shape=(seq_len,))\n",
    "\n",
    "    # Embedding layers\n",
    "    src_embed = Embedding(src_vocab_size, d_model)(src_inputs)\n",
    "    tgt_embed = Embedding(tgt_vocab_size, d_model)(tgt_inputs)\n",
    "\n",
    "    # Add positional encoding\n",
    "    src_embed = PositionalEncoding(seq_len, d_model)(src_embed)\n",
    "    tgt_embed = PositionalEncoding(seq_len, d_model)(tgt_embed)\n",
    "\n",
    "    # Transformer encoder layers\n",
    "    for _ in range(num_layers):\n",
    "        src_embed = transformer_encoder(src_embed, num_heads, d_model, ff_dim)\n",
    "\n",
    "    # Transformer decoder layers\n",
    "    for _ in range(num_layers):\n",
    "        tgt_embed = transformer_encoder(tgt_embed, num_heads, d_model, ff_dim)\n",
    "\n",
    "    # Final dense layer for prediction\n",
    "    output = Dense(tgt_vocab_size, activation='softmax')(tgt_embed)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = tf.keras.models.Model(inputs=[src_inputs, tgt_inputs], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define model parameters\n",
    "src_vocab_size = len(src_tokenizer.word_index) + 1\n",
    "tgt_vocab_size = len(tgt_tokenizer.word_index) + 1\n",
    "seq_len = MAX_SEQ_LEN  # Set this according to the maximum sentence length\n",
    "\n",
    "# Build and compile the model\n",
    "model = transformer_model(src_vocab_size, tgt_vocab_size, seq_len)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the target sequence to prepare for teacher forcing (for training)\n",
    "y_train_input = y_train[:, :-1]\n",
    "y_train_output = y_train[:, 1:]\n",
    "\n",
    "y_val_input = y_val[:, :-1]\n",
    "y_val_output = y_val[:, 1:]\n",
    "\n",
    "y_train_input = np.pad(y_train_input, ((0, 0), (0, 1)), mode='constant')\n",
    "y_val_input = np.pad(y_val_input, ((0, 0), (0, 1)), mode='constant')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\engine\\training.py\", line 998, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\engine\\training.py\", line 1092, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 605, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 143, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 700, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\metrics\\metrics.py\", line 3669, in sparse_categorical_accuracy\n        matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 970, in sparse_categorical_matches\n        matches = tf.cast(tf.equal(y_true, y_pred), backend.floatx())\n\n    ValueError: Dimensions must be equal, but are 48 and 49 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](Squeeze, Cast_2)' with input shapes: [?,48], [?,49].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_input\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_input\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file95ingzk4.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\engine\\training.py\", line 998, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\engine\\training.py\", line 1092, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 605, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 143, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 700, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\metrics\\metrics.py\", line 3669, in sparse_categorical_accuracy\n        matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"c:\\Users\\admin\\anaconda\\envs\\vision\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 970, in sparse_categorical_matches\n        matches = tf.cast(tf.equal(y_true, y_pred), backend.floatx())\n\n    ValueError: Dimensions must be equal, but are 48 and 49 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](Squeeze, Cast_2)' with input shapes: [?,48], [?,49].\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    [x_train, y_train_input],\n",
    "    np.expand_dims(y_train_output, -1),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=([x_val, y_val_input], np.expand_dims(y_val_output, -1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 49)\n",
      "(1, 49)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_input.shape)  # Should print something like (1, 50)\n",
    "print(y_val_input.shape)    # Should print something like (1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def translate_sequence(model, input_seq, src_tokenizer, tgt_tokenizer):\n",
    "    # Prepare the input sequence and target sequence for the decoder\n",
    "    input_seq = pad_sequences([input_seq], maxlen=MAX_SEQ_LEN, padding='post')\n",
    "    start_token = np.array([START_TOKEN])\n",
    "    \n",
    "    # Get initial model prediction\n",
    "    decoded_sentence = []\n",
    "    for _ in range(MAX_SEQ_LEN):\n",
    "        prediction = model.predict([input_seq, start_token])\n",
    "        predicted_token = np.argmax(prediction[0, -1, :])\n",
    "        decoded_sentence.append(predicted_token)\n",
    "        \n",
    "        # If we reach the end token, break\n",
    "        if predicted_token == END_TOKEN:\n",
    "            break\n",
    "        \n",
    "        start_token = np.array([predicted_token])\n",
    "    \n",
    "    return ' '.join(tgt_tokenizer.sequences_to_texts([decoded_sentence]))\n",
    "\n",
    "# Example Translation\n",
    "swiss_german_sentence = \"I bi am abend\"\n",
    "swiss_german_seq = src_tokenizer.texts_to_sequences([swiss_german_sentence])\n",
    "translated = translate_sequence(model, swiss_german_seq[0], src_tokenizer, tgt_tokenizer)\n",
    "print(\"Translated:\", translated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
